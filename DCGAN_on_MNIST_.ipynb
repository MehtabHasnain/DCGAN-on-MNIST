{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DCGAN on MNIST .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4GVaDSlOSf"
      },
      "source": [
        "import torch \n",
        "torch.manual_seed(42)\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwklBE_vlOSi"
      },
      "source": [
        "# Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oUWVmkulOSi"
      },
      "source": [
        "device = 'cuda' # image = image.to(device)\n",
        "\n",
        "batch_size = 128  # trainloader , taining loop\n",
        " \n",
        "noise_dim = 64  #generator model\n",
        "\n",
        "#optimizers parameters\n",
        "\n",
        "lr= 0.0002\n",
        "beta_1 = 0.5\n",
        "beta_2 = 0.99\n",
        "\n",
        "#Training variables\n",
        "\n",
        "epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thRDmRxBlOSj"
      },
      "source": [
        "# Load MNIST Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA70KkPWlOSj"
      },
      "source": [
        "from torchvision import datasets, transforms as T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RPRGJDAlOSk"
      },
      "source": [
        "train_augs = T.Compose([T.RandomRotation((-20, +20)),\n",
        "                        T.ToTensor()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORt5m1TvlOSk"
      },
      "source": [
        "\n",
        "trainset = datasets.MNIST('MNIST/',download = True, train = True, transform= train_augs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN8OGFATlOSk"
      },
      "source": [
        "image, label =trainset [9000]\n",
        "plt.imshow(image.squeeze(),cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRSk3zV1lOSl"
      },
      "source": [
        "# Load Dataset Into Batches "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaRQzZhr7-HF"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDNysctVlOSl"
      },
      "source": [
        "trainloader = DataLoader(trainset , batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me1C0THUlOSm"
      },
      "source": [
        "len(trainloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter (trainloader)\n",
        "\n",
        "images, _ =dataiter.next()\n",
        "print(images.shape)"
      ],
      "metadata": {
        "id": "yGzs3DjP426c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R3XRbXBlOSm"
      },
      "source": [
        "# 'show_tensor_images' : function is used to plot some of images from the batch\n",
        "\n",
        "def show_tensor_images(tensor_img, num_images = 16, size=(1, 28, 28)):\n",
        "    unflat_img = tensor_img.detach().cpu()\n",
        "    img_grid = make_grid(unflat_img[:num_images], nrow=4)\n",
        "    plt.imshow(img_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVLG2TA4lOSm"
      },
      "source": [
        "show_tensor_images(images, num_images =16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb1rVzijlOSn"
      },
      "source": [
        "# Create Discriminator Network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22qSpIBlknec"
      },
      "source": [
        "#In case if torch summary is not installed \n",
        "\n",
        "from torch import nn\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYvzxU2llOSn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtQoJvmrAxTj"
      },
      "source": [
        "'''\n",
        "\n",
        "Network : Discriminator\n",
        "\n",
        "input : (bs, 1, 28, 28)\n",
        "      |                                                                                               ---- SUMMARY ----\n",
        "      V\n",
        "Conv2d( in_channels = 1, out_channels = 16, kernel_size = (3,3), stride = 2)                           #(bs, 16, 13, 13)\n",
        "BatchNorm2d()                                                                                          #(bs, 16, 13, 13)\n",
        "LeakyReLU()                                                                                            #(bs, 16, 13, 13)\n",
        "      |\n",
        "      V\n",
        "Conv2d( in_channels = 16, out_channels = 32, kernel_size = (5,5), stride = 2)                          #(bs, 32, 5, 5)\n",
        "BatchNorm2d()                                                                                          #(bs, 32, 5, 5)\n",
        "LeakyReLU()                                                                                            #(bs, 32, 5, 5)\n",
        "      |\n",
        "      V\n",
        "Conv2d( in_channels = 32, out_channels = 64, kernel_size = (5,5), stride = 2)                          #(bs, 64, 1, 1)\n",
        "BatchNorm2d()                                                                                          #(bs, 64, 1, 1)\n",
        "LeakyReLU()                                                                                            #(bs, 64, 1, 1)\n",
        "      |\n",
        "      V\n",
        "Flatten()                                                                                              #(bs, 64)\n",
        "Linear(in_features = 64, out_features = 1)                                                             #(bs, 1)\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VpIDdx9lOSn"
      },
      "source": [
        "def get_disc_block(in_channels,out_channels, kernel_size, stride) :\n",
        "  return nn.Sequential (\n",
        "      nn.Conv2d(in_channels, out_channels, kernel_size, stride),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.LeakyReLU(0.2)\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq_aX7EslOSo"
      },
      "source": [
        "class Discriminator(nn.Module) :\n",
        "\n",
        "  def __init__(self) :\n",
        "      super(Discriminator,self).__init__()\n",
        "\n",
        "      self.block_1 = get_disc_block(1,16, (3,3),2)\n",
        "      self.block_2 = get_disc_block(16,32, (5,5),2)\n",
        "      self.block_3 = get_disc_block(32,64, (5,5),2)\n",
        "\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.linear = nn.Linear (in_features= 64, out_features= 1)\n",
        "\n",
        "  def forward(self,images):\n",
        "\n",
        "     x1= self.block_1(images)\n",
        "     x2= self.block_2(x1)\n",
        "     x3= self.block_3 (x2)\n",
        "\n",
        "     x4= self.flatten(x3)\n",
        "     x5= self.linear(x4)\n",
        "\n",
        "     return x5     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqZFM47slOSo"
      },
      "source": [
        "D = Discriminator()\n",
        "D.to(device)\n",
        "\n",
        "summary(D, input_size= (1,28,28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaSM5ky-lOSp"
      },
      "source": [
        "# Create Generator Network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeBHYF5IAzFm"
      },
      "source": [
        "'''\n",
        "\n",
        "Network : Generator \n",
        "\n",
        "z_dim = 64\n",
        "input : (bs,z_dim)\n",
        "\n",
        "      |\n",
        "      | Reshape\n",
        "      V\n",
        "\n",
        "input : (bs, channel, height, width) -> (bs, z_dim , 1 , 1) \n",
        "      |                                                                                               ---- SUMMARY ----\n",
        "      V\n",
        "ConvTranspose2d( in_channels = z_dim, out_channels = 256, kernel_size = (3,3), stride = 2)             #(bs, 256, 3, 3)\n",
        "BatchNorm2d()                                                                                          #(bs, 256, 3, 3)\n",
        "ReLU()                                                                                                 #(bs, 256, 3, 3)\n",
        "      |\n",
        "      V\n",
        "ConvTranspose2d( in_channels = 256, out_channels = 128, kernel_size = (4,4), stride = 1)               #(bs, 128, 6, 6)\n",
        "BatchNorm2d()                                                                                          #(bs, 128, 6, 6)\n",
        "ReLU()                                                                                                 #(bs, 128, 6, 6)\n",
        "      |\n",
        "      V\n",
        "ConvTranspose2d( in_channels = 128, out_channels = 64, kernel_size = (3,3), stride = 2)                #(bs, 64, 13, 13)\n",
        "BatchNorm2d()                                                                                          #(bs, 64, 13, 13)\n",
        "ReLU()                                                                                                 #(bs, 64, 13, 13)\n",
        "      |\n",
        "      V\n",
        "ConvTranspose2d( in_channels = 64, out_channels = 1, kernel_size = (4,4), stride = 2)                  #(bs, 1, 28, 28)\n",
        "Tanh()                                                                                                 #(bs, 1, 28, 28)\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmGinLUjlOSp"
      },
      "source": [
        "def get_gen_block(in_channels, out_channels, kernel_size, stride, final_block = False):\n",
        "  if final_block == True:\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels,out_channels,kernel_size,stride),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "    \n",
        "  return nn.Sequential(\n",
        "      nn.ConvTranspose2d(in_channels,out_channels, kernel_size,stride),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.ReLU()\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNcWK2malOSq"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self,noise_dim) :\n",
        "      super(Generator,self).__init__()\n",
        "\n",
        "      self.noise_dim= noise_dim\n",
        "\n",
        "      self.block_1 =get_disc_block(noise_dim,256,(3,3),2)\n",
        "      self.block_2 =get_disc_block(256,128,(4,4),1)\n",
        "      self.block_3 =get_disc_block(128,64,(3,3),2)\n",
        "\n",
        "      self.block_4 =get_disc_block(64,1,(4,4),2,final_block = True)\n",
        "\n",
        "  def forward(self, r_noise_vec) :\n",
        "\n",
        "    #(bs,noise_dim) -> (bs,noise_dim, 1 ,1 )\n",
        "    x= r_noise_vec.view(-1,self.noise_dim,1,1)\n",
        "\n",
        "    x1 = self.block_1(x)\n",
        "    x2 = self.block_2(x1)\n",
        "    x3 = self.block_3(x2)\n",
        "    x4 = self.block4(x3)\n",
        "\n",
        "    return x4    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyOp5x61lOSr",
        "scrolled": true
      },
      "source": [
        "G = Generator (noise_dim)\n",
        "G.to(device)\n",
        "\n",
        "summary(G, input_size = ( 1 , noise_dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6v-NfQlVy8v"
      },
      "source": [
        "# Replace Random initialized weights to Normal weights  \n",
        "\n",
        "def weights_init(m):  \n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpMoglmaUPnt"
      },
      "source": [
        "D = D.apply(weights_init)\n",
        "G = G.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLGG2YkRlOSr"
      },
      "source": [
        "# Create Loss Function and Load Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOvcqBuylOSs"
      },
      "source": [
        "def real_loss(disc_pred):\n",
        "  criterion= nn.BCEWithLogitsLoss()\n",
        "  ground_truth= torch.ones_like(disc_pred)\n",
        "  loss = criterion (disc_pred, ground_truth)\n",
        "  return loss\n",
        "\n",
        "def fake_loss(disc_pred):\n",
        "  criterion= nn.BCEWithLogitsLoss()\n",
        "  ground_truth= torch.zeros_like(disc_pred)\n",
        "  loss = criterion (disc_pred, ground_truth)\n",
        "  return loss  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96EEpkp9lOSs"
      },
      "source": [
        "D_opt = torch.optim.Adam(D.parameters(), lr=lr,betas= (beta_1,beta_2))\n",
        "G_opt = torch.optim.Adam(G.parameters(), lr=lr,betas= (beta_1,beta_2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF_k10LElOSt"
      },
      "source": [
        "# Training Loop "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmPLh41ulOSt"
      },
      "source": [
        "for 1 in range (epochs):\n",
        "  total_d_loss = 0.0\n",
        "  total_g_loss = 0.0\n",
        "\n",
        "  for real_img, _in tqdm(trainloader):\n",
        "    real_img = real_imag.to(device)\n",
        "    noise = torch.randn(batch_size, noise_dim, device= device)\n",
        "#loss and weights for D\n",
        "   D.opt.zero_grad()\n",
        "\n",
        "   fake_imag = G(noise)\n",
        "\n",
        "   D_pred = D(fake_img)\n",
        "   D_fake_loss = fake_loss(D_pred)\n",
        "\n",
        "   D_pred = D(real_img)\n",
        "   D_real_loss = real_loss(D_pred) \n",
        "\n",
        "   D_loss = (D_fake_loss + D_real_loss)/2\n",
        "   total_d_loss += D_loss.tem()\n",
        "   D_loss.backward()\n",
        "   D_opt.stop()\n",
        "\n",
        "#loss and weights for G\n",
        "   G.opt.zero_grad()\n",
        "   noise = torch.randn(batch_size, noise_dim, device= device)\n",
        "\n",
        "   fake_img = G(noise)\n",
        "\n",
        "   D_pred = D(fake_img)\n",
        "   G_loss = real_loss(D_pred)\n",
        "   \n",
        "   total_g_loss += G_loss.tem()\n",
        "\n",
        "   G_loss.backward()\n",
        "\n",
        " avg_d_loss = total_d_loss / len(trainloader)\n",
        " avg_g_loss = total_g_loss / len(trainloader)\n",
        "\n",
        " print(\"Epoch : {} | D_loss {} | G_loss {}\".format(i+1, avg_d_loss, avg_g_loss))\n",
        " show _tensor_images(fake_img)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1IjTM2sliWa"
      },
      "source": [
        "\n",
        "\n",
        "noise = torch.randn(batch_size, noise_dim, device = device)\n",
        "generated_image = G(noise)\n",
        "\n",
        "show_tensor_images(generated_image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}